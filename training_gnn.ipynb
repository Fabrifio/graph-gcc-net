{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define names of datasets to select\n",
    "dataset_target_name_list = [\"ENZYMES\", \"DD\"]\n",
    "\n",
    "# Define datasets destination\n",
    "datasets_folder = \"datasets/\"\n",
    "\n",
    "# List of all datasets names\n",
    "dataset_name_list = os.listdir(datasets_folder)\n",
    "\n",
    "# List of dataset files and label files\n",
    "dataset_file_list = []\n",
    "dataset_label_file_list = []\n",
    "\n",
    "# File paths of dataset edge indexes and labels\n",
    "for dataset_name in dataset_name_list:\n",
    "    if(dataset_name in dataset_target_name_list):\n",
    "        dataset_file_list.append(os.path.join(datasets_folder, dataset_name, f\"{dataset_name}.pth\"))\n",
    "        dataset_label_file_list.append(os.path.join(datasets_folder, dataset_name, f\"{dataset_name}.global_cc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable gpu for training, validation and test if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of datasets\n",
    "dataset_list = []\n",
    "\n",
    "# List of dataset labels list\n",
    "dataset_labels_list = []\n",
    "\n",
    "for dataset_file, dataset_label_file in zip(dataset_file_list, dataset_label_file_list):\n",
    "    # Load dataset\n",
    "    dataset = torch.load(dataset_file, weights_only=True)\n",
    "\n",
    "    # Load labels from file .global_cc\n",
    "    with open(dataset_label_file, 'r') as f:\n",
    "        dataset_labels = [float(line.strip()) for line in f.readlines()]\n",
    "\n",
    "    # Prepare dataset list to manage datasets easily\n",
    "    dataset_list.append(dataset)\n",
    "\n",
    "    # Prepare dataset labels\n",
    "    dataset_labels_list.append(dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structure for storing Data object of graphs\n",
    "data_list = []\n",
    "\n",
    "# Create pytorch geometric Data objects from graphs\n",
    "for dataset, dataset_labels in zip(dataset_list, dataset_labels_list):\n",
    "    for i, (key, tensor) in enumerate(dataset.items()):\n",
    "        edge_index = tensor.coalesce().indices()\n",
    "        label = torch.tensor([dataset_labels[i]])\n",
    "        data = Data(edge_index=edge_index, y=label)\n",
    "\n",
    "        # Add node features to current graph's Data object\n",
    "        x = degree(edge_index[0], data.num_nodes, dtype=torch.float).view(-1, 1)\n",
    "        data.x = x\n",
    "\n",
    "        data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader split in train, validation and test\n",
    "total_len = len(data_list)\n",
    "train_len = int(0.8 * total_len)\n",
    "validation_len = int(0.1 * total_len)\n",
    "test_len = total_len - train_len - validation_len\n",
    "\n",
    "train_data, validation_data, test_data = random_split(data_list, [train_len, validation_len, test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader structures for train, valdation and test\n",
    "train_data_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "validation_data_loader = DataLoader(validation_data, batch_size=32, shuffle=True)\n",
    "test_data_loader = DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as func\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN model representation\n",
    "class ClusteringCoefficientGNN(torch.nn.Module):\n",
    "    # Model architecture\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(ClusteringCoefficientGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.linear = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    # Forward pass (inference)\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Graph convolutional layers\n",
    "        x = self.conv1(x, edge_index)  \n",
    "        x = func.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = func.relu(x)\n",
    "\n",
    "        # Global mean pool (graph-level features)\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # Fully connected layer\n",
    "        x = self.linear(x)\n",
    "        x = func.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_data_loader, optimizer, loss_function):\n",
    "    # Set GNN model to training mode\n",
    "    model.train()\n",
    "    train_total_loss = 0\n",
    "\n",
    "    # Train over all graphs in training_data_loader\n",
    "    for data in train_data_loader:\n",
    "        # Clear the gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move data to device (gpu if available)\n",
    "        data = data.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(out.squeeze(dim=1), data.y)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_total_loss += loss.item()\n",
    "\n",
    "    return train_total_loss / len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function (for validation and test)\n",
    "@torch.no_grad()\n",
    "def evaluate(model, evaluation_data_loader, loss_function):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    evaluation_total_loss = 0\n",
    "\n",
    "    # Evaluation over all graphs in evaluation_data_loader\n",
    "    for data in evaluation_data_loader:\n",
    "        # Move data to device (gpu if available)\n",
    "        data = data.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(out.squeeze(dim=1), data.y)\n",
    "\n",
    "        evaluation_total_loss += loss.item()\n",
    "\n",
    "    return evaluation_total_loss / len(evaluation_data_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of node features\n",
    "in_channels = 1\n",
    "\n",
    "# Output dimension (regression task over scalar numbers)\n",
    "out_channels = 1\n",
    "\n",
    "# Hyperparameters for GNN\n",
    "hidden_channels = 64\n",
    "\n",
    "# Training settings\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "patience = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ClusteringCoefficientGNN(in_channels, hidden_channels, out_channels)\n",
    "model.to(device)\n",
    "\n",
    "# Initialize optimizer and loss function\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Train Loss: 0.2374, Val Loss: 0.2353\n",
      "Epoch 002, Train Loss: 0.2373, Val Loss: 0.2358\n",
      "Epoch 003, Train Loss: 0.2374, Val Loss: 0.2355\n",
      "Epoch 004, Train Loss: 0.2374, Val Loss: 0.2356\n",
      "Patience finished: stopping training\n",
      "Test Loss: 0.2365\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs the GNN has not obtained better validation loss\n",
    "patience_counter = 0\n",
    "\n",
    "# Best validation loss up to now\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "# Training and validation loop\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Training step\n",
    "    train_loss = train(model, train_data_loader, optimizer, loss_function)\n",
    "\n",
    "    # Validation step\n",
    "    val_loss = evaluate(model, validation_data_loader, loss_function)\n",
    "\n",
    "    # Training status in current epoch\n",
    "    print(f'Epoch {epoch:03d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Early stopping condition using patience\n",
    "    if(val_loss < best_validation_loss):\n",
    "        best_validation_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if(patience_counter == patience):\n",
    "            print(\"Patience finished: stopping training\")\n",
    "            break\n",
    "\n",
    "# Final test phase\n",
    "test_loss = evaluate(model, test_data_loader, loss_function)\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save location in 'model/'\n",
    "model_folder = \"model/\"\n",
    "os.makedirs(model_folder, exist_ok = True)\n",
    "\n",
    "# Save GNN model\n",
    "torch.save(model.state_dict(), os.path.join(model_folder, 'graph_gcc_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0164], device='cuda:0')\n",
      "tensor([[0.4954]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "index = 4\n",
    "data_point = data_list[index].to(device)\n",
    "out = model(data_point.x, data_point.edge_index, data.batch)\n",
    "print(data_list[index].y)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
