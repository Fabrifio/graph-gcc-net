{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset name\n",
    "dataset_name = \"COLLAB\"\n",
    "\n",
    "# Define datasets destination\n",
    "datasets_folder = \"datasets/\"\n",
    "os.makedirs(datasets_folder, exist_ok = True)\n",
    "\n",
    "# File paths of edge list and node IDs list\n",
    "edges_file = os.path.join(datasets_folder, dataset_name, f\"{dataset_name}.edges\")\n",
    "graph_idx_file =  os.path.join(datasets_folder, dataset_name, f\"{dataset_name}.graph_idx\")\n",
    "\n",
    "# Load edge list and node IDs list\n",
    "edges = np.loadtxt(edges_file, dtype=int, delimiter=\",\")\n",
    "graph_idx = np.loadtxt(graph_idx_file, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for Node2Vec\n",
    "\n",
    "# Set dimension of node embeddings\n",
    "embedding_dim = 5\n",
    "\n",
    "# Set length and number of random walks\n",
    "walk_length = 5\n",
    "walks_per_node = 10\n",
    "\n",
    "# Set context size for Skip-Gram\n",
    "context_size = 5\n",
    "\n",
    "# Set number of trainig epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Set learning rate\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available for training Node2Vec\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train procedure for Node2Vec\n",
    "def train(node2vec, loader, optimizer):\n",
    "    # Set Node2Vec model to training mode\n",
    "    node2vec.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Run training epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Iterate over random walk samples\n",
    "        for pos_rw, neg_rw in loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = node2vec.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss = total_loss + loss.item()\n",
    "    \n",
    "    # Return training loss\n",
    "    return total_loss / num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Node2Vec\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep node IDs file and edges file row indexes to read graphs sequentially\n",
    "nodes_file_row = 0\n",
    "edges_file_row = 0\n",
    "\n",
    "# Extract graph ids\n",
    "unique_graph_ids = np.unique(graph_idx)\n",
    "\n",
    "# Data structure for storing graphs\n",
    "graphs = []\n",
    "\n",
    "# Dictionary of node embeddings tensors\n",
    "graph_node_embeddings = {}\n",
    "\n",
    "# Sequence number associated to the current graph\n",
    "seq_num = 0\n",
    "\n",
    "# Total number of nodes\n",
    "tot_num_nodes = 0\n",
    "\n",
    "for current_graph_id in unique_graph_ids:\n",
    "\n",
    "    # Data structure for soring node IDs and edges\n",
    "    current_graph_node_ids = []\n",
    "    current_graph_edges = []\n",
    "\n",
    "    # Extract node IDs of current graph\n",
    "    for idx, graph_id in enumerate(graph_idx[nodes_file_row:], start = nodes_file_row):\n",
    "        if(graph_id == current_graph_id):\n",
    "            current_graph_node_ids.append(idx + 1)\n",
    "        else:\n",
    "            nodes_file_row = nodes_file_row + len(current_graph_node_ids)\n",
    "            break\n",
    "\n",
    "    # Number of nodes of the current graph\n",
    "    N = len(current_graph_node_ids)\n",
    "\n",
    "    # Initialize data strucutres to store sparse adjacency matrix\n",
    "    indices = []\n",
    "\n",
    "    # Structure to store edges already in the current graph\n",
    "    seen_edges = set()\n",
    "    \n",
    "    # Extract edges of current graph\n",
    "    for row, col in edges[edges_file_row:]:\n",
    "        if row in current_graph_node_ids and col in current_graph_node_ids:\n",
    "            \n",
    "            # Sort edge tuple to check if is already present\n",
    "            edge = tuple(sorted((row, col)))        \n",
    "            if(edge not in seen_edges):\n",
    "                current_graph_edges.append((row, col))\n",
    "                seen_edges.add(edge)\n",
    "                \n",
    "                # Add indices for the sparse tensor\n",
    "                indices.append([row - 1 - tot_num_nodes, col - 1 - tot_num_nodes])\n",
    "\n",
    "            # Count at which row we are reading the file\n",
    "            edges_file_row = edges_file_row + 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Convert indices and values to tensors\n",
    "    indices = torch.tensor(indices, dtype=torch.long).t()\n",
    "\n",
    "    # Symmetrize adjacency matrix\n",
    "    reversed_indices = indices.flip(0)\n",
    "    indices = torch.cat([indices, reversed_indices], dim=1)\n",
    "\n",
    "    # Create Pytorch Geometric Data object for Node2Vec\n",
    "    num_nodes = len(current_graph_node_ids)\n",
    "    data = Data(edge_index=indices, num_nodes=num_nodes)\n",
    "    data = data.to(device)\n",
    "    \n",
    "    # Initialize Node2Vec model\n",
    "    node2vec = Node2Vec(\n",
    "        edge_index=data.edge_index,\n",
    "        embedding_dim=embedding_dim,\n",
    "        walk_length=walk_length,\n",
    "        context_size=context_size,\n",
    "        walks_per_node=walks_per_node,\n",
    "        num_negative_samples=1,\n",
    "        sparse=True\n",
    "    )\n",
    "\n",
    "    # Move Node2Vec model to GPU\n",
    "    node2vec = node2vec.to(device) \n",
    "\n",
    "    # Create DataLoader object\n",
    "    loader = node2vec.loader(batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "    # Define optimizer to train Node2Vec\n",
    "    optimizer = torch.optim.SparseAdam(list(node2vec.parameters()), lr=learning_rate)\n",
    "\n",
    "    # Train Node2Vec\n",
    "    avg_loss = train(node2vec, loader, optimizer)\n",
    "\n",
    "    # Compute node embeddings\n",
    "    embeddings = node2vec.embedding.weight.detach().to(device)\n",
    "\n",
    "    # Compute normalized degree of each node\n",
    "    num_nodes = data.edge_index.max().item() + 1\n",
    "    normalized_degrees = degree(data.edge_index[0], num_nodes, dtype=torch.float) / num_nodes\n",
    "    normalized_degrees = normalized_degrees.view(-1, 1)\n",
    "\n",
    "    # Concatenate node embeddings and normalized degree\n",
    "    node_features = torch.cat([embeddings, normalized_degrees], dim=1)\n",
    "\n",
    "    # Store node embeddings of current graph\n",
    "    graph_node_embeddings[current_graph_id] = node_features\n",
    "\n",
    "    # Total number of nodes among all previous graphs\n",
    "    tot_num_nodes = tot_num_nodes + N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name where to save graph tensors\n",
    "output_file =  os.path.join(datasets_folder, dataset_name, f\"{dataset_name}.pt\")\n",
    "\n",
    "# Save graph tensors in .pt file\n",
    "torch.save(graph_node_embeddings, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
